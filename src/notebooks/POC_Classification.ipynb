{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection Orthogonal Complement Classifier\n",
    "\n",
    "In this notebook, we show how to use the Projection onto the Orthogonal Complement pipeline to classify handritten digits, both in the pixel and scattering domain.\n",
    "Furthermore, we use a validation approach in order to optimize the model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import kymatio as km\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from lib.data.data_loading import ClassificationDataset\n",
    "from lib.data.data_processing import convert_images_to_scat\n",
    "from lib.utils.visualizations import display_subset_data, visualize_accuracy_landscape\n",
    "from lib.projections.projection_orthogonal_complement import get_features_all_classes, \\\n",
    "    extract_cluster_features, projections_classifier, optimize_dimensionality\n",
    "from CONFIG import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macros and global variables\n",
    "STANDARIZE = True  # standarizing features to hvae zero-mean and unit-variance\n",
    "MAX_DIMS = 200  # maximum nubmer of directions to consider\n",
    "STEP = 20  # step for considering distances (e.g., [20, 40, 60, ...])\n",
    "DATASET = \"svhn\"  # dataset used for classification ['mnist', 'svhn']\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT_PATH = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "DATA_PATH = os.path.join(ROOT_PATH, CONFIG[\"paths\"][\"data_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the Data\n",
    "\n",
    "In this section, we load the data from the MNIST dataset and compute the scattering representation from the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/corrales/Work/Generalization Deep Learning/scattering_mnist/data/train_32x32.mat\n",
      "Using downloaded and verified file: /home/corrales/Work/Generalization Deep Learning/scattering_mnist/data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# loading all mnist data\n",
    "mnist_dataset = ClassificationDataset(data_path=DATA_PATH, dataset_name=DATASET, valid_size=0.25) \n",
    "train_imgs, train_labels = mnist_dataset.train_data, mnist_dataset.train_labels\n",
    "valid_imgs, valid_labels = mnist_dataset.valid_data, mnist_dataset.valid_labels\n",
    "test_imgs, test_labels = mnist_dataset.test_data, mnist_dataset.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the scattering network\n",
    "J = 3  # spatial field of the kernel is 2**J \n",
    "L = 6  # number of angles in the kernel\n",
    "shape = (32,32)  # shape of the input images\n",
    "max_order = 2 # depth of the network\n",
    "scattering_layer = km.Scattering2D(J=J, shape=shape, max_order=max_order, L=L)\n",
    "if DEVICE.type == 'cuda':\n",
    "    scattering_layer = scattering_layer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train-set images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 13/859 [00:01<01:33,  9.02it/s]"
     ]
    }
   ],
   "source": [
    "# computing the scattering transform of all images\n",
    "print(\"Processing train-set images...\")\n",
    "train_scat_features = convert_images_to_scat(images=train_imgs, scattering=scattering_layer, device=DEVICE, equalize=True)\n",
    "print(\"Processing valid-set images...\")\n",
    "valid_scat_features = convert_images_to_scat(images=valid_imgs, scattering=scattering_layer, device=DEVICE, equalize=True)\n",
    "print(\"Processing test-set images...\")\n",
    "test_scat_features = convert_images_to_scat(images=test_imgs, scattering=scattering_layer, device=DEVICE, equalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_subset_data(imgs=train_imgs, labels=train_labels, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Extraction\n",
    "\n",
    "In this section, we perform the feature extraction steps of the POC algorithm. Namely, we extract the class prototypes and the eigenvectors of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_ids = np.arange(10).tolist()\n",
    "\n",
    "# extracting features for the data in the pixel domain\n",
    "img_classwise_data, img_prototypes,\\\n",
    "    img_eigenvectors = get_features_all_classes(data=train_imgs, labels=train_labels, verbose=1,\n",
    "                                                cluster_ids=cluster_ids, standarize=False)\n",
    "\n",
    "# extracting features for the scattering in the pixel domain\n",
    "scat_classwise_data, scat_prototypes,\\\n",
    "    scat_eigenvectors = get_features_all_classes(data=train_scat_features, labels=train_labels, verbose=1,\n",
    "                                                 cluster_ids=cluster_ids, standarize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image Classification\n",
    "\n",
    "In this third section we focus on the image classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Parameter Optimization\n",
    "\n",
    "First, we use the validation set to optimize the model parameters, i.e., the number of directions to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_candidates = np.arange(0, MAX_DIMS, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing for the image domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dims_img, max_acc_img,\\\n",
    "    accuracies_img = optimize_dimensionality(data=valid_imgs, labels=valid_labels,\n",
    "                                             dims=direction_candidates, \n",
    "                                             prototypes=img_prototypes,\n",
    "                                             eigenvectors=img_eigenvectors,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dims = max(0, opt_dims_img - 10)\n",
    "max_dims = min(MAX_DIMS, opt_dims_img + 11)\n",
    "fine_direction_candidates = np.arange(min_dims, max_dims)\n",
    "\n",
    "fine_opt_dims_img, fine_max_acc_img,\\\n",
    "    fine_accuracies_img = optimize_dimensionality(data=valid_imgs, labels=valid_labels,\n",
    "                                                  dims=fine_direction_candidates, \n",
    "                                                  prototypes=img_prototypes,\n",
    "                                                  eigenvectors=img_eigenvectors, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18,5)\n",
    "fig.suptitle(\"Accuracy on the image domain using the POC algorithm for different number of removed directions\", fontsize=14)\n",
    "visualize_accuracy_landscape(xaxis=direction_candidates, accuracy=accuracies_img, \n",
    "                             ax=ax[0], xlabel=\"Directions Removed\", ylabel=\"Accuracy\",\n",
    "                             title=\"Accuracy for all tested directions\", grid=True)\n",
    "visualize_accuracy_landscape(xaxis=fine_direction_candidates, accuracy=fine_accuracies_img, \n",
    "                             ax=ax[1], xlabel=\"Directions Removed\", ylabel=\"Accuracy\",\n",
    "                             title=\"Zoomed in on maximum accuracy area\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing for the scattering domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_candidates = np.arange(0, MAX_DIMS, STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dims_scat, max_acc_scat,\\\n",
    "    accuracies_scat = optimize_dimensionality(data=valid_scat_features, labels=valid_labels,\n",
    "                                             dims=direction_candidates, \n",
    "                                             prototypes=scat_prototypes,\n",
    "                                             eigenvectors=scat_eigenvectors,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dims = max(0, opt_dims_scat - 10)\n",
    "max_dims = min(MAX_DIMS, opt_dims_scat + 11)\n",
    "fine_direction_candidates = np.arange(min_dims, max_dims)\n",
    "\n",
    "fine_opt_dims_scat, fine_max_acc_scat,\\\n",
    "    fine_accuracies_scat = optimize_dimensionality(data=valid_scat_features, labels=valid_labels,\n",
    "                                                   dims=fine_direction_candidates, \n",
    "                                                   prototypes=scat_prototypes,\n",
    "                                                   eigenvectors=scat_eigenvectors,\n",
    "                                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18,5)\n",
    "fig.suptitle(\"Accuracy on the scattering domain using the POC algorithm for different number of removed directions\", fontsize=14)\n",
    "visualize_accuracy_landscape(xaxis=direction_candidates, accuracy=accuracies_scat, \n",
    "                             ax=ax[0], xlabel=\"Directions Removed\", ylabel=\"Accuracy\",\n",
    "                             title=\"Accuracy for all tested directions\", grid=True)\n",
    "visualize_accuracy_landscape(xaxis=fine_direction_candidates, accuracy=fine_accuracies_scat, \n",
    "                             ax=ax[1], xlabel=\"Directions Removed\", ylabel=\"Accuracy\",\n",
    "                             title=\"Zoomed in on maximum accuracy area\", grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Test Set Evaluation\n",
    "\n",
    "We now use the features extracted from the training set and the parameters optimized on the validation set to classify the images from the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_labels_img, _ = projections_classifier(points=test_imgs,\n",
    "                                                 prototypes=img_prototypes,\n",
    "                                                 eigenvectors=img_eigenvectors,\n",
    "                                                 n_directions=fine_opt_dims_img)\n",
    "\n",
    "n_correct_labels_img = len(np.where(pred_test_labels_img == test_labels.numpy())[0])\n",
    "test_set_acc_img = 100 * n_correct_labels_img / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_labels_scat, _ = projections_classifier(points=test_scat_features,\n",
    "                                                  prototypes=scat_prototypes,\n",
    "                                                  eigenvectors=scat_eigenvectors,\n",
    "                                                  n_directions=fine_opt_dims_scat)\n",
    "\n",
    "n_correct_labels_scat = len(np.where(pred_test_labels_scat == test_labels.numpy())[0])\n",
    "test_set_acc_scat = 100 * n_correct_labels_scat / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test set accuracy results:\")\n",
    "print(f\"    Img Domain:  {round(test_set_acc_img, 3)}%\")\n",
    "print(f\"    Scat Domain: {round(test_set_acc_scat, 3)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=alert style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "   This notebook was created by <b>Angel Villar-Corrales</b>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
